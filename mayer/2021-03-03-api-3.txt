
mentální model (představa) => komunikace => API => implementace




    STRUCTURE (struct) --------- BLOB (data)
        - smooth only



we need jagged   (vector<string>)




HDD <----> RAM <----> GPU_RAM


1) data jsou serializovatelná do sekvence chunků
2) jeden chunk se vejde do GPU

(HDD data) --GRINDER--> (sequence of chunks)


GRINDER = split the problem to smaller problems that fit onto the GPU
COMPOSER = GRINDER^(-1)


MAP + REDUCE


    item, chunk, dataset
    |----------|
       kernel      cpu




chunk = self contained (by definition), small problem



                                  ** MAP **

dataset --LOADER--> chunk --KERNEL--> output-chunk --SAVER--> output-dataset


                                ** REDUCE **

dataset --LOADER--> chunk --MAP(kernel)--> output-chunk --REDUCE(kernel)--> result




+ -------------------------------------------------------------------------------+
|                                 GRAND POZOROVÁNÍ                               |
+ -------------------------------------------------------------------------------+
| High-level budeme zpracovávat data stejně, jako databáze. Tzn. že budeme       |
| mít proudy dat a ty budeme kombinovat pomocí výpočetních uzlů. Rozdíl je ten,  |
| že některé uzly bude muset implementovat uživatel.                             |
+ -------------------------------------------------------------------------------+

Základní duhy uzlů:
- LOADER(user_impl)
- MAP(user_kernel)
- REDUCE(user_kernel)
- SAVER(user_impl)


                        !! COMPUTATION & DATA_MODELLING !!
                            = pipeline     = structs

Jagged data! Nejsou nutná, stačí když z (vector<string>) uděláme jeden chunk na každej string.
Není to ideální, ale je to schůdné. Kdyby se někdo nudil, tak může přidat top-level jagged data
do structur, ale potom by stejně mely ty jagged data být v jednom blobu.

Z toho ale plyne, že chunky nemusí mít stejnou velikost (často mít budou, ale nemusí).
Takže je třeba trochu tancovat okolo alokace bufferů na GPU. Ale stačí nafukovat, ezy.



// histogram over one large grayscale image
// (je to pseudokód jak prase, ale co)

template<typename TChunk>
class my_loader : noarr::loader {
    IEnumerable<TChunk> get_chunks() {
        img image = load_from_disk("/path/...");
        for (i in chunks of img)
            yield chunk(i, img);
    }
}

__global__ void mapping_kernel() {
    // 1 chunk to 1 histogram
    .......
}

__global__ void reducing_kernel() {
    // N histograms to 1 histogram
    .......
}

int main() {
    auto chunk_structure = noarr::vector<''. ... scalar<char> ...>();

    // build the computation pipeline
    auto l = my_loader<typeof(chunk_structure)>();
    auto m = noarr::map(l, &mapping_kernel);
    auto r = noarr::reduce(m, &reducing_kernel)
    
    // run the pipeline to completion
    auto histogram = r.run_to_completion();

    // done
    print(histogram);
}
